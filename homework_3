#!/bin/bash

# Input data
You have log file 'access.log' with the following format:

remote-ip - - [date] "method query protocol" status-code object-size "referrer" "user-agent" "x-forwarded-for"
 

object-size - the size of the object returned to the client
referrer    - the location where the client came from
user-agent  - information about client browser

Sample can be downloaded from http://www.almhuette-raith.at/apache-log/access.log (~650 Mb)

# Tasks

### Awk /ɔːk/
1. What is the most frequent browser?
# первая же трудность, к которой столкнулся - нужно правильно разделить колонки в файле и правильно и однозначно определить для себя колонку "user-agent", потому что в ней содержится информацйия об используемом браузере. В условиях не указано какая именно информация указана в поле "user-agent", но первым значением там является браузер, и затем какие-то дополнительные данные. Буду считать, что дополнительные данные для задания не важны и мне нужен только браузер.
# для отладки я использовал tail -n 15 access.log, чисто чтобы проверить работу команды awk только на последних скольких-то значениях, но учитывать это в итоге не буду
awk -F " \"|\" " '{print $5}' access.log #я вычленяю колонку "user-agent", отделяемую знаками " \"" или "\" "
awk -F " \"|\" " '{print $5}' access.log  | sort | uniq -c # сортирует, а затем считает количество повторяющихся значений и выводит сначала число повторений этих значений (uniq -c), а потом остальную часть колонки
awk -F " \"|\" " '{print $5}' access.log  | sort | uniq -c | awk '{print $1, $2}' | sort -n # оставим только первый и второй столбцы, т.е. количество повторений значения, а затем используемый браузер, и тогда чем дальше вниз, тем большее число будет. sort -n нужно, чтобы не было чисел вроде 3 44 55 6 67 - будет происходить сортировка строк linux по числовому значению
awk -F " \"|\" " '{print $5}' access.log  | sort | uniq -c | awk '{print $1, $2}' | sort -n | tail -n 1 # итоговая команда, tail -n выводит последнее самое большое число.
# уверен, можно было сделать какой-то счетчик для самого часто повторяющегося варианта, или же сделать строчку проще, но я слишком много времени потратил на то, чтобы разобраться как работает разделение столбцов и как вычленить конкретно тот, что мне нужен, поэтому оставил такой вариант.

2. Show number of requests per month for ip 216.244.66.230 (for example: Sep 2016 - 100500 reqs, Oct 2016 - 0 reqs, Nov 2016 - 2 reqs...)
# вот так выйдет отсортировать самые важные столбцы для начала: remote-ip [date]. Здесь [date] попаала в 2 столбца №4 и №5 из-за разделителя в виде пробела, но мне не так важно это - главное их отсортировать от остальных, а они достаточно структурированы, в отличие от прошлого задания.
awk '{print $1, $4, $5}' access.log | awk '$1=="216.244.66.230" {print}' #вывожу нужные мне столбцы, остортировываю по первому все нужные ip-адреса
awk '{print $1, $4, $5}' access.log | awk -F " |[|/|:|]" '$1=="216.244.66.230" {print}' #модифицирую команду, чтобы можно было выводить любой нужный столбец внутри [date]
awk '{print $1, $4, $5}' access.log | awk -F " |[|/|:|]" '$1=="216.244.66.230" {print "reqs - ", $3, $4}' | uniq -c # uniq -c в конце поставит перед выборкой количество совпадающих по месяцу запросов. Можно сделать бы чуть более красиво, как-то оформить, но я постарался приблизиться к примеру по выводу

3. Show total amount of data which server has provided for each unique ip (i.e. 100500 bytes for 1.2.3.4; 9001 bytes for 5.4.3.2 and so on)
awk -F " - - |[|]| \"|\" " '{print $1, $4}' access.log # для начала выведу нужные мне столбцы с адекватным разделением. Хоть и есть лишние значения, но я от них избавлюсь, главное чтобы не перепуталось
awk -F " - - |[|]| \"|\" " '{print $1, $4}' access.log | awk '{ same[$1] += $3 } END { for (i in same) print same[i], "bytes for", i }' # честно, нашел такое решение в интернете и не до конца понимаю принцип его работы, но смог адаптировать под свою задачу и оно выводит что надо. "{same[$1]+=$3} создает hash-карту с $1, обрабатываемым значением индекса, и сумма увеличивается только для тех уникальных элементов из $1 в файле"

### Sed
1. Change all browsers to "lynx"
# не совсем понятно в каком виде это нужно вывести. Я могу сделать так:
tail access.log | awk -F " \"|\" " '{print $5}' | awk '{print $1}' | sed 's/.*/lynx/' #пока что вывожу только хвост лога, но суть не в этом. Это меняет именно столбец с именами браузеров, и по сути задача выполнена, но уверен, это не то что нужно, потому что я даже не вижу смысла в таком действии. Попробую выполнить по-другому.
# если бы нужно было в выводе из файла заменить всю колонку с браузерами на колонку со значениями "lynx", то можно было бы сделать так, без использования sed:
tail -n 1 access.log | awk -F " \"|\" " '$5="\"lynx\"" {print}' #потом результат вывода можно направить в файл.
#в итоге я не смог найти каким образом можно было бы заменить именно столбец с браузерами на свой, используя команду sed, т.к. в столбце могут бытиь разные данные, а сам столбец сложно извлекать даже командой awk. Пытался найти рещение как в sed поместить вывод команды awk как входные данные для замены этих входных данных на свои в исходном файле, но не смог выяснить возможно ли такое в принципе. Можно было бы вычленить нужный столбец по образцу, но мне нужно бы заменить всё ПОСЛЕ определенных символов, как например после образца [^\"][:space:]\".*\"[:space:]\" - это бы указывавло именно на столбец с браузерами, но слишком сложный выходит способ, да и sed заменяет указанные значения.

2. Masquerade all ip addresses. Rewrite file.
# не совсем понял что имеется ввиду под словом masquerade - замаскировать т.е. скрыть, т.е. заменить чем-то другим, что не будет "палить" ip-адреса? Или прогнать определенной маской?
tail -n 15 access.log | awk '{print}' | sed 's/[0-9\.]*/xxx\.xxx\.xxx\.xxx/' #замаскировал все ip адреса в начале текстом xxx.xxx.xxx.xxx
#если выводить весь файл целиком, то команда будет такой:
awk '{print}' access.log | sed 's/[0-9\.]*/xxx\.xxx\.xxx\.xxx/' > access.log #в конце отправляю переписывать файл
#или можно обойтись только командой sed, перезаписав файл (можно на всякйи случай сделать бэкап
sed -i.backup 's/[0-9\.]*/xxx\.xxx\.xxx\.xxx/' access.log
