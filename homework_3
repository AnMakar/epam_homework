#!/bin/bash

# Input data
You have log file 'access.log' with the following format:

remote-ip - - [date] "method query protocol" status-code object-size "referrer" "user-agent" "x-forwarded-for"
 

object-size - the size of the object returned to the client
referrer    - the location where the client came from
user-agent  - information about client browser

Sample can be downloaded from http://www.almhuette-raith.at/apache-log/access.log (~650 Mb)

# Tasks

### Awk /ɔːk/
1. What is the most frequent browser?
# первая же трудность, к которой столкнулся - нужно правильно разделить колонки в файле и правильно и однозначно определить для себя колонку "user-agent", потому что в ней содержится информацйия об используемом браузере. В условиях не указано какая именно информация указана в поле "user-agent", но первым значением там является браузер, и затем какие-то дополнительные данные. Буду считать, что дополнительные данные для задания не важны и мне нужен только браузер.
# для отладки я использовал tail -n 15 access.log, чисто чтобы проверить работу команды awk только на последних скольких-то значениях, но учитывать это в итоге не буду
awk -F " \"|\" " '{print $5}' access.log #я вычленяю колонку "user-agent", отделяемую знаками " \"" или "\" "
awk -F " \"|\" " '{print $5}' access.log  | sort | uniq -c # сортирует, а затем считает количество повторяющихся значений и выводит сначала число повторений этих значений (uniq -c), а потом остальную часть колонки
awk -F " \"|\" " '{print $5}' access.log  | sort | uniq -c | awk '{print $1, $2}' | sort -n # оставим только первый и второй столбцы, т.е. количество повторений значения, а затем используемый браузер, и тогда чем дальше вниз, тем большее число будет. sort -n нужно, чтобы не было чисел вроде 3 44 55 6 67 - будет происходить сортировка строк linux по числовому значению
awk -F " \"|\" " '{print $5}' access.log  | sort | uniq -c | awk '{print $1, $2}' | sort -n | tail -n 1 # итоговая команда, tail -n выводит последнее самое большое число.
# уверен, можно было сделать какой-то счетчик для самого часто повторяющегося варианта, или же сделать строчку проще, но я слишком много времени потратил на то, чтобы разобраться как работает разделение столбцов и как вычленить конкретно тот, что мне нужен, поэтому оставил такой вариант.

2. Show number of requests per month for ip 216.244.66.230 (for example: Sep 2016 - 100500 reqs, Oct 2016 - 0 reqs, Nov 2016 - 2 reqs...)
# вот так выйдет отсортировать самые важные столбцы для начала: remote-ip [date]. Здесь [date] попаала в 2 столбца №4 и №5 из-за разделителя в виде пробела, но мне не так важно это - главное их отсортировать от остальных, а они достаточно структурированы, в отличие от прошлого задания.
awk '{print $1, $4, $5}' access.log | awk '$1=="216.244.66.230" {print}' #вывожу нужные мне столбцы, остортировываю по первому все нужные ip-адреса
awk '{print $1, $4, $5}' access.log | awk -F " |[|/|:|]" '$1=="216.244.66.230" {print}' #модифицирую команду, чтобы можно было выводить любой нужный столбец внутри [date]
awk '{print $1, $4, $5}' access.log | awk -F " |[|/|:|]" '$1=="216.244.66.230" {print "reqs - ", $3, $4}' | uniq -c # uniq -c в конце поставит перед выборкой количество совпадающих по месяцу запросов. Можно сделать бы чуть более красиво, как-то оформить, но я постарался приблизиться к примеру по выводу

3. Show total amount of data which server has provided for each unique ip (i.e. 100500 bytes for 1.2.3.4; 9001 bytes for 5.4.3.2 and so on)
awk -F " - - |[|]| \"|\" " '{print $1, $4}' access.log # для начала выведу нужные мне столбцы с адекватным разделением. Хоть и есть лишние значения, но я от них избавлюсь, главное чтобы не перепуталось
awk -F " - - |[|]| \"|\" " '{print $1, $4}' access.log | awk '{ same[$1] += $3 } END { for (i in same) print same[i], "bytes for", i }' # честно, нашел такое решение в интернете и не до конца понимаю принцип его работы, но смог адаптировать под свою задачу и оно выводит что надо. "{same[$1]+=$3} создает hash-карту с $1, обрабатываемым значением индекса, и сумма увеличивается только для тех уникальных элементов из $1 в файле"
